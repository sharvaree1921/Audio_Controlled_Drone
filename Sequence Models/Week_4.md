### Transformers

#### Transformers Network Intuition

One of the very very important architectures in the NLP model.
Transformers Network allows you to compute all of these complicated complications in a parallel manner rather than sequentially from left to right as in RNN or LSTM.
RNN process one outtput at a time which contrasts with a CNN which takes in input a lot of pixels simultaneously(or in parallel). 

![t1](https://github.com/sharvaree1921/Audio_Controlled_Drone/blob/main/Images/Screenshot%20from%202021-06-27%2016-55-47.png)

So, Attention+CNN is the attention. Self Attention and Multi-Headed Attention are its two types.

![t2](https://github.com/sharvaree1921/Audio_Controlled_Drone/blob/main/Images/Screenshot%20from%202021-06-27%2017-01-16.png)


